__base__:
  - __base__/base.yaml
  - __base__/accelerator.yaml
  - __base__/hub.yaml
  - __base__/mono3drefer_dataset.yaml

# Accelerator
with_tracking: True
report_to: 'wandb'
project_name: 'mono3dvg-v2'
mixed_precision: 'no'

# Dataset
dataset:
  root_dir: './Mono3DRefer/'

model:
  num_labels: 9

  # Backbone
  use_timm_backbone: True
  backbone: 'swin_large_patch4_window7_224'
  pretrained_backbone_path: 'pretrained-models/swin_large_patch4_window7_224/model.safetensors'
  num_feature_levels: 4

  # Text Encoder
  text_encoder_type: 'pretrained-models/roberta-base'
  num_text_output_layers: 1

  # Vision-Language Encoder
  vl_encoder_type: 'fusion'
  
  # Transformer
  with_box_refine: True
  two_stage: False
  use_dab: True
  encoder_layers: 3
  decoder_layers: 1
  d_model: 256
  encoder_ffn_dim: 256
  decoder_ffn_dim: 256
  num_queries: 1
  decoder_self_attn: False
  decoder_depth_residual: False
  decoder_text_residual: False
  use_text_guided_adapter: True

learning_rate: 1.0e-4
lr_scheduler:
  type: cosine
  num_warmup_steps: 500
  # decay_rate: 0.1
  # decay_list: [40]

# Training
output_dir: outputs/vl-swin-dab
num_train_epochs: 60
dataloader_num_workers: 0
train_batch_size: &batch_size 12
valid_batch_size: *batch_size
test_batch_size: *batch_size
mono3dvg_model: 'pretrained-models/mono3dvg-vl-swin-dab/checkpoint_best.pth'
pretrain_model: 'outputs/vl-swin-dab/checkpoints/best'
